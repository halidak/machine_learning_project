{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8150114,"sourceType":"datasetVersion","datasetId":4820098}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport torch\nimport torch.nn as nn\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-16T17:06:38.584893Z","iopub.execute_input":"2024-05-16T17:06:38.585311Z","iopub.status.idle":"2024-05-16T17:06:38.591334Z","shell.execute_reply.started":"2024-05-16T17:06:38.585280Z","shell.execute_reply":"2024-05-16T17:06:38.590177Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-05-16T17:06:38.593553Z","iopub.execute_input":"2024-05-16T17:06:38.594023Z","iopub.status.idle":"2024-05-16T17:06:38.602320Z","shell.execute_reply.started":"2024-05-16T17:06:38.593984Z","shell.execute_reply":"2024-05-16T17:06:38.601013Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"dataRegular = pd.read_csv('/kaggle/input/pulsar-classification-for-class-prediction-cleaned/Pulsar_cleaned.csv', index_col=[0])\ncolumn_to_exclude = 'Class'\ndataRegular = dataRegular.head(1000);\n# Extract list of columns\ndata_cols = list(dataRegular.columns)\nprint('Dataset columns: {}'.format(data_cols))","metadata":{"execution":{"iopub.status.busy":"2024-05-16T17:06:38.604751Z","iopub.execute_input":"2024-05-16T17:06:38.605455Z","iopub.status.idle":"2024-05-16T17:06:38.651567Z","shell.execute_reply.started":"2024-05-16T17:06:38.605413Z","shell.execute_reply":"2024-05-16T17:06:38.650033Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Dataset columns: ['EK', 'Skewness', 'Mean_DMSNR_Curve', 'SD_DMSNR_Curve', 'EK_DMSNR_Curve', 'Skewness_DMSNR_Curve', 'Class']\n","output_type":"stream"}]},{"cell_type":"code","source":"column_name = 'EK'\nnum_negative_values = (dataRegular[column_name] < 0).sum()\n\nprint(f\"The column '{column_name}' has {num_negative_values} negative values.\")","metadata":{"execution":{"iopub.status.busy":"2024-05-16T17:06:38.653170Z","iopub.execute_input":"2024-05-16T17:06:38.653543Z","iopub.status.idle":"2024-05-16T17:06:38.660980Z","shell.execute_reply.started":"2024-05-16T17:06:38.653502Z","shell.execute_reply":"2024-05-16T17:06:38.659502Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"The column 'EK' has 0 negative values.\n","output_type":"stream"}]},{"cell_type":"code","source":"n = 14987","metadata":{"execution":{"iopub.status.busy":"2024-05-16T17:06:38.663662Z","iopub.execute_input":"2024-05-16T17:06:38.664144Z","iopub.status.idle":"2024-05-16T17:06:38.669859Z","shell.execute_reply.started":"2024-05-16T17:06:38.664113Z","shell.execute_reply":"2024-05-16T17:06:38.668588Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"data = torch.tensor(dataRegular.values, dtype=torch.float32).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T17:06:38.671018Z","iopub.execute_input":"2024-05-16T17:06:38.671729Z","iopub.status.idle":"2024-05-16T17:06:38.683081Z","shell.execute_reply.started":"2024-05-16T17:06:38.671698Z","shell.execute_reply":"2024-05-16T17:06:38.681988Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(7, 50),\n            nn.ReLU(),\n            nn.Linear(50, 7)\n        )\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T17:06:38.685988Z","iopub.execute_input":"2024-05-16T17:06:38.687253Z","iopub.status.idle":"2024-05-16T17:06:38.694829Z","shell.execute_reply.started":"2024-05-16T17:06:38.687206Z","shell.execute_reply":"2024-05-16T17:06:38.693636Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(7, 50),\n            nn.ReLU(),\n            nn.Linear(50, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T17:06:38.698877Z","iopub.execute_input":"2024-05-16T17:06:38.699212Z","iopub.status.idle":"2024-05-16T17:06:38.708471Z","shell.execute_reply.started":"2024-05-16T17:06:38.699187Z","shell.execute_reply":"2024-05-16T17:06:38.707350Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"generator = Generator().to(device)\ndiscriminator = Discriminator().to(device)\n\n# Loss and optimizers\ncriterion = nn.BCELoss()\noptimizer_g = torch.optim.Adam(generator.parameters(), lr=0.001)\noptimizer_d = torch.optim.Adam(discriminator.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T17:06:38.710015Z","iopub.execute_input":"2024-05-16T17:06:38.710475Z","iopub.status.idle":"2024-05-16T17:06:38.722344Z","shell.execute_reply.started":"2024-05-16T17:06:38.710436Z","shell.execute_reply":"2024-05-16T17:06:38.721311Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"num_epochs = 59948\nbatch_size = 1000  # Define your batch size\n\nfor epoch in range(num_epochs):\n    # Train discriminator\n    optimizer_d.zero_grad()\n    \n    # Sample a random batch of real data\n    indices = torch.randperm(data.size(0))[:batch_size]\n    real_data = data[indices]\n    real_labels = torch.ones(batch_size, 1).to(device)  # Adjust label size to match batch size\n\n    # Forward pass through discriminator for real data\n    outputs_real = discriminator(real_data)\n    d_loss_real = criterion(outputs_real, real_labels)\n\n    # Similarly, sample a random batch of noise for fake data\n    noise = torch.randn(batch_size, 7).to(device)\n    fake_data = generator(noise)\n    fake_labels = torch.zeros(batch_size, 1).to(device)  # Adjust label size to match batch size\n\n    # Forward pass through discriminator for fake data\n    outputs_fake = discriminator(fake_data.detach())  # Detach to avoid backprop through generator\n    d_loss_fake = criterion(outputs_fake, fake_labels)\n\n    # Calculate total discriminator loss\n    d_loss = d_loss_real + d_loss_fake\n    \n    # Backward pass and optimization for discriminator\n    d_loss.backward()\n    optimizer_d.step()\n\n    # Train generator\n    optimizer_g.zero_grad()\n\n    # Generate fake data\n    noise = torch.randn(batch_size, 7).to(device)\n    fake_data = generator(noise)\n\n    # Labels for the generator (all ones, as we want to fool the discriminator)\n    gen_labels = torch.ones(batch_size, 1).to(device)\n\n    # Forward pass through discriminator for fake data (no detach needed here)\n    outputs = discriminator(fake_data)\n\n    # Calculate generator loss\n    g_loss = criterion(outputs, gen_labels)\n\n    # Backward pass and optimization for generator\n    g_loss.backward()\n    optimizer_g.step()\n\n    # Print losses\n    if (epoch+1) % 1000 == 0:\n        print(f\"Epoch [{epoch+1}/{num_epochs}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-16T17:06:38.725345Z","iopub.execute_input":"2024-05-16T17:06:38.726131Z","iopub.status.idle":"2024-05-16T17:10:22.004243Z","shell.execute_reply.started":"2024-05-16T17:06:38.726084Z","shell.execute_reply":"2024-05-16T17:10:22.003097Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Epoch [1000/59948], d_loss: 0.8528, g_loss: 3.1275\nEpoch [2000/59948], d_loss: 1.1607, g_loss: 1.3230\nEpoch [3000/59948], d_loss: 1.4415, g_loss: 0.8289\nEpoch [4000/59948], d_loss: 0.9960, g_loss: 1.3960\nEpoch [5000/59948], d_loss: 1.0652, g_loss: 1.0916\nEpoch [6000/59948], d_loss: 1.5607, g_loss: 0.7492\nEpoch [7000/59948], d_loss: 0.9989, g_loss: 1.1843\nEpoch [8000/59948], d_loss: 1.9098, g_loss: 0.6517\nEpoch [9000/59948], d_loss: 1.2129, g_loss: 1.0738\nEpoch [10000/59948], d_loss: 0.8543, g_loss: 1.2454\nEpoch [11000/59948], d_loss: 1.4961, g_loss: 0.7028\nEpoch [12000/59948], d_loss: 1.6187, g_loss: 0.7356\nEpoch [13000/59948], d_loss: 1.7662, g_loss: 0.6144\nEpoch [14000/59948], d_loss: 1.2414, g_loss: 0.7974\nEpoch [15000/59948], d_loss: 1.5565, g_loss: 0.6122\nEpoch [16000/59948], d_loss: 1.4428, g_loss: 0.7425\nEpoch [17000/59948], d_loss: 0.9989, g_loss: 1.0014\nEpoch [18000/59948], d_loss: 1.1646, g_loss: 0.8796\nEpoch [19000/59948], d_loss: 1.0751, g_loss: 0.9464\nEpoch [20000/59948], d_loss: 1.2495, g_loss: 0.8162\nEpoch [21000/59948], d_loss: 0.9553, g_loss: 1.0924\nEpoch [22000/59948], d_loss: 1.4351, g_loss: 0.7337\nEpoch [23000/59948], d_loss: 2.2355, g_loss: 0.4213\nEpoch [24000/59948], d_loss: 1.2864, g_loss: 0.7529\nEpoch [25000/59948], d_loss: 1.7297, g_loss: 0.5654\nEpoch [26000/59948], d_loss: 1.4746, g_loss: 0.7556\nEpoch [27000/59948], d_loss: 1.7414, g_loss: 0.5050\nEpoch [28000/59948], d_loss: 1.4694, g_loss: 0.6864\nEpoch [29000/59948], d_loss: 1.9628, g_loss: 0.5784\nEpoch [30000/59948], d_loss: 1.5391, g_loss: 0.7202\nEpoch [31000/59948], d_loss: 1.5271, g_loss: 0.6553\nEpoch [32000/59948], d_loss: 1.3631, g_loss: 0.7523\nEpoch [33000/59948], d_loss: 2.2157, g_loss: 0.7043\nEpoch [34000/59948], d_loss: 1.8077, g_loss: 0.5441\nEpoch [35000/59948], d_loss: 1.3190, g_loss: 0.8399\nEpoch [36000/59948], d_loss: 1.4783, g_loss: 0.8116\nEpoch [37000/59948], d_loss: 1.5143, g_loss: 0.6712\nEpoch [38000/59948], d_loss: 1.5419, g_loss: 0.8090\nEpoch [39000/59948], d_loss: 0.9187, g_loss: 1.0374\nEpoch [40000/59948], d_loss: 1.2551, g_loss: 0.8141\nEpoch [41000/59948], d_loss: 1.2786, g_loss: 0.7970\nEpoch [42000/59948], d_loss: 1.5349, g_loss: 0.6315\nEpoch [43000/59948], d_loss: 1.5673, g_loss: 0.5942\nEpoch [44000/59948], d_loss: 1.2506, g_loss: 0.8538\nEpoch [45000/59948], d_loss: 1.3310, g_loss: 0.7767\nEpoch [46000/59948], d_loss: 1.8631, g_loss: 0.5591\nEpoch [47000/59948], d_loss: 1.4587, g_loss: 0.6383\nEpoch [48000/59948], d_loss: 1.5092, g_loss: 0.7031\nEpoch [49000/59948], d_loss: 1.2239, g_loss: 0.8227\nEpoch [50000/59948], d_loss: 0.8930, g_loss: 1.0758\nEpoch [51000/59948], d_loss: 1.3731, g_loss: 0.7293\nEpoch [52000/59948], d_loss: 1.8080, g_loss: 0.5591\nEpoch [53000/59948], d_loss: 1.3634, g_loss: 0.7388\nEpoch [54000/59948], d_loss: 1.4154, g_loss: 0.7500\nEpoch [55000/59948], d_loss: 1.0297, g_loss: 0.9273\nEpoch [56000/59948], d_loss: 1.3103, g_loss: 0.8205\nEpoch [57000/59948], d_loss: 0.8850, g_loss: 1.0947\nEpoch [58000/59948], d_loss: 1.3211, g_loss: 0.7347\nEpoch [59000/59948], d_loss: 1.3566, g_loss: 0.7333\n","output_type":"stream"}]},{"cell_type":"code","source":"# After training, generate some synthetic data\nwith torch.no_grad():\n    test_noise = torch.randn(n, 7).to(device)\n    generated_data = generator(test_noise).cpu().numpy()\n\n# Print the first 10 rows of generated data\nprint(\"Generated Data (First 10 rows):\")\nfor i in range(10):\n    print(generated_data[i])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T17:10:28.396959Z","iopub.execute_input":"2024-05-16T17:10:28.397365Z","iopub.status.idle":"2024-05-16T17:10:28.410720Z","shell.execute_reply.started":"2024-05-16T17:10:28.397332Z","shell.execute_reply":"2024-05-16T17:10:28.409503Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Generated Data (First 10 rows):\n[-2.9681918e-01  1.0031540e+00  2.0251722e+00  3.5118515e+01\n  2.0136461e+01  3.2089490e+02  4.3688032e-01]\n[ 0.04682364  0.2830529   0.8552967  12.878707    3.832282   35.880733\n  0.10641435]\n[-0.25088254  0.26982954  0.6077123  14.402217    7.01315    98.40495\n  0.15741426]\n[ 0.1802651   0.5250217   1.2741059  18.310177    7.4375772  97.65476\n  0.18637349]\n[-4.0521946e-02  2.0876279e-01  6.7777133e-01  1.3576564e+01\n  5.8237782e+00  7.4783218e+01  1.3858923e-01]\n[ -0.4313601    0.4780166   -0.20185645  13.825994     8.136069\n 120.84089      0.17103374]\n[  0.42920446   0.86656094   2.3039644   30.004452    12.939145\n 189.39601      0.36777666]\n[ 0.13230881  0.50894594  1.1787046  15.245796    3.8341026  35.7682\n  0.12431557]\n[ 0.11960083  0.21583596  0.64479274 12.566814    5.1564317  61.053493\n  0.12727572]\n[  0.18275192   0.3647568    1.1969388   17.197601     7.5651674\n 103.07168      0.1819869 ]\n","output_type":"stream"}]}]}