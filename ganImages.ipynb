{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], d_loss: 3.9767, g_loss: 3.3528\n",
      "Epoch [2/200], d_loss: 3.9866, g_loss: 3.0944\n",
      "Epoch [3/200], d_loss: 1.5659, g_loss: 4.4386\n",
      "Epoch [4/200], d_loss: 3.2458, g_loss: 3.3559\n",
      "Epoch [5/200], d_loss: 1.9341, g_loss: 5.6958\n",
      "Epoch [6/200], d_loss: 2.4373, g_loss: 4.4269\n",
      "Epoch [7/200], d_loss: 1.4021, g_loss: 3.2238\n",
      "Epoch [8/200], d_loss: 3.6241, g_loss: 3.4346\n",
      "Epoch [9/200], d_loss: 1.2627, g_loss: 4.6803\n",
      "Epoch [10/200], d_loss: 0.9283, g_loss: 4.6461\n",
      "Epoch [11/200], d_loss: 1.1793, g_loss: 4.4108\n",
      "Epoch [12/200], d_loss: 1.2570, g_loss: 2.8733\n",
      "Epoch [13/200], d_loss: 0.8859, g_loss: 3.5905\n",
      "Epoch [14/200], d_loss: 1.3366, g_loss: 5.0472\n",
      "Epoch [15/200], d_loss: 0.9898, g_loss: 4.2321\n",
      "Epoch [16/200], d_loss: 1.5553, g_loss: 5.7283\n",
      "Epoch [17/200], d_loss: 0.8747, g_loss: 3.8123\n",
      "Epoch [18/200], d_loss: 1.2297, g_loss: 3.7787\n",
      "Epoch [19/200], d_loss: 2.0158, g_loss: 5.2593\n",
      "Epoch [20/200], d_loss: 4.1505, g_loss: 4.9614\n",
      "Epoch [21/200], d_loss: 0.6697, g_loss: 5.9829\n",
      "Epoch [22/200], d_loss: 0.6044, g_loss: 4.1185\n",
      "Epoch [23/200], d_loss: 0.8303, g_loss: 7.0446\n",
      "Epoch [24/200], d_loss: 4.6622, g_loss: 5.3326\n",
      "Epoch [25/200], d_loss: 7.4022, g_loss: 4.5432\n",
      "Epoch [26/200], d_loss: 4.8340, g_loss: 5.3606\n",
      "Epoch [27/200], d_loss: 3.4925, g_loss: 5.7175\n",
      "Epoch [28/200], d_loss: 2.2531, g_loss: 8.5498\n",
      "Epoch [29/200], d_loss: 6.9879, g_loss: 2.9091\n",
      "Epoch [30/200], d_loss: 3.6070, g_loss: 8.1730\n",
      "Epoch [31/200], d_loss: 2.3896, g_loss: 5.9451\n",
      "Epoch [32/200], d_loss: 2.2597, g_loss: 4.1652\n",
      "Epoch [33/200], d_loss: 1.5585, g_loss: 4.1352\n",
      "Epoch [34/200], d_loss: 2.9874, g_loss: 4.7477\n",
      "Epoch [35/200], d_loss: 1.1877, g_loss: 5.3747\n",
      "Epoch [36/200], d_loss: 3.1112, g_loss: 3.5631\n",
      "Epoch [37/200], d_loss: 0.6770, g_loss: 2.8249\n",
      "Epoch [38/200], d_loss: 2.1776, g_loss: 1.7092\n",
      "Epoch [39/200], d_loss: 1.4906, g_loss: 1.0042\n",
      "Epoch [40/200], d_loss: 1.4485, g_loss: 1.1863\n",
      "Epoch [41/200], d_loss: 1.6181, g_loss: 1.4317\n",
      "Epoch [42/200], d_loss: 1.5193, g_loss: 2.3425\n",
      "Epoch [43/200], d_loss: 1.1047, g_loss: 3.5600\n",
      "Epoch [44/200], d_loss: 0.7647, g_loss: 2.6438\n",
      "Epoch [45/200], d_loss: 0.9767, g_loss: 1.3840\n",
      "Epoch [46/200], d_loss: 2.6659, g_loss: 3.2201\n",
      "Epoch [47/200], d_loss: 0.6680, g_loss: 2.8479\n",
      "Epoch [48/200], d_loss: 0.7050, g_loss: 2.3063\n",
      "Epoch [49/200], d_loss: 0.5325, g_loss: 3.1795\n",
      "Epoch [50/200], d_loss: 1.1938, g_loss: 3.7480\n",
      "Epoch [51/200], d_loss: 1.0730, g_loss: 3.0839\n",
      "Epoch [52/200], d_loss: 0.8205, g_loss: 2.7575\n",
      "Epoch [53/200], d_loss: 1.6058, g_loss: 3.9427\n",
      "Epoch [54/200], d_loss: 0.5414, g_loss: 2.3489\n",
      "Epoch [55/200], d_loss: 1.0184, g_loss: 2.4339\n",
      "Epoch [56/200], d_loss: 1.2143, g_loss: 4.5950\n",
      "Epoch [57/200], d_loss: 1.9209, g_loss: 5.2112\n",
      "Epoch [58/200], d_loss: 1.1364, g_loss: 6.9778\n",
      "Epoch [59/200], d_loss: 1.4210, g_loss: 6.9640\n",
      "Epoch [60/200], d_loss: 1.7979, g_loss: 4.6072\n",
      "Epoch [61/200], d_loss: 1.8021, g_loss: 4.9711\n",
      "Epoch [62/200], d_loss: 1.7868, g_loss: 3.8286\n",
      "Epoch [63/200], d_loss: 1.0867, g_loss: 4.5821\n",
      "Epoch [64/200], d_loss: 0.5713, g_loss: 4.4840\n",
      "Epoch [65/200], d_loss: 0.4995, g_loss: 4.2251\n",
      "Epoch [66/200], d_loss: 0.6873, g_loss: 3.4121\n",
      "Epoch [67/200], d_loss: 1.7124, g_loss: 2.4781\n",
      "Epoch [68/200], d_loss: 0.7434, g_loss: 2.8206\n",
      "Epoch [69/200], d_loss: 2.2450, g_loss: 4.1566\n",
      "Epoch [70/200], d_loss: 1.4005, g_loss: 6.0026\n",
      "Epoch [71/200], d_loss: 2.8274, g_loss: 5.6725\n",
      "Epoch [72/200], d_loss: 2.8369, g_loss: 1.4314\n",
      "Epoch [73/200], d_loss: 1.5925, g_loss: 4.5651\n",
      "Epoch [74/200], d_loss: 2.3011, g_loss: 4.3383\n",
      "Epoch [75/200], d_loss: 2.2515, g_loss: 4.9418\n",
      "Epoch [76/200], d_loss: 2.1401, g_loss: 2.1279\n",
      "Epoch [77/200], d_loss: 1.7498, g_loss: 3.7881\n",
      "Epoch [78/200], d_loss: 1.3495, g_loss: 3.4922\n",
      "Epoch [79/200], d_loss: 2.2251, g_loss: 4.2255\n",
      "Epoch [80/200], d_loss: 0.9330, g_loss: 2.5424\n",
      "Epoch [81/200], d_loss: 0.7461, g_loss: 4.1603\n",
      "Epoch [82/200], d_loss: 1.3028, g_loss: 6.3692\n",
      "Epoch [83/200], d_loss: 3.2740, g_loss: 1.5958\n",
      "Epoch [84/200], d_loss: 2.3914, g_loss: 0.5058\n",
      "Epoch [85/200], d_loss: 2.1009, g_loss: 3.2713\n",
      "Epoch [86/200], d_loss: 1.1531, g_loss: 3.0301\n",
      "Epoch [87/200], d_loss: 1.4208, g_loss: 3.0163\n",
      "Epoch [88/200], d_loss: 1.0191, g_loss: 1.8552\n",
      "Epoch [89/200], d_loss: 1.2466, g_loss: 0.3718\n",
      "Epoch [90/200], d_loss: 2.5855, g_loss: 4.7855\n",
      "Epoch [91/200], d_loss: 2.2019, g_loss: 1.4469\n",
      "Epoch [92/200], d_loss: 1.3812, g_loss: 1.3434\n",
      "Epoch [93/200], d_loss: 1.7517, g_loss: 2.9334\n",
      "Epoch [94/200], d_loss: 2.4362, g_loss: 1.1468\n",
      "Epoch [95/200], d_loss: 4.1562, g_loss: 2.0868\n",
      "Epoch [96/200], d_loss: 3.2042, g_loss: 2.3641\n",
      "Epoch [97/200], d_loss: 0.9836, g_loss: 3.7552\n",
      "Epoch [98/200], d_loss: 1.4589, g_loss: 2.2320\n",
      "Epoch [99/200], d_loss: 1.2922, g_loss: 2.4456\n",
      "Epoch [100/200], d_loss: 1.8034, g_loss: 3.8781\n",
      "Epoch [101/200], d_loss: 1.4060, g_loss: 2.8267\n",
      "Epoch [102/200], d_loss: 0.8185, g_loss: 1.9664\n",
      "Epoch [103/200], d_loss: 0.8735, g_loss: 2.2104\n",
      "Epoch [104/200], d_loss: 0.7595, g_loss: 2.7046\n",
      "Epoch [105/200], d_loss: 3.2333, g_loss: 0.9662\n",
      "Epoch [106/200], d_loss: 1.2709, g_loss: 3.0761\n",
      "Epoch [107/200], d_loss: 0.9212, g_loss: 3.6811\n",
      "Epoch [108/200], d_loss: 1.4871, g_loss: 3.6037\n",
      "Epoch [109/200], d_loss: 1.4353, g_loss: 2.6820\n",
      "Epoch [110/200], d_loss: 1.4931, g_loss: 2.1327\n",
      "Epoch [111/200], d_loss: 1.5378, g_loss: 2.3381\n",
      "Epoch [112/200], d_loss: 1.4665, g_loss: 3.1504\n",
      "Epoch [113/200], d_loss: 1.4672, g_loss: 2.9901\n",
      "Epoch [114/200], d_loss: 4.2201, g_loss: 2.7473\n",
      "Epoch [115/200], d_loss: 0.8821, g_loss: 2.3932\n",
      "Epoch [116/200], d_loss: 1.2054, g_loss: 3.9932\n",
      "Epoch [117/200], d_loss: 3.4576, g_loss: 5.0472\n",
      "Epoch [118/200], d_loss: 1.6189, g_loss: 3.8979\n",
      "Epoch [119/200], d_loss: 2.3526, g_loss: 0.4822\n",
      "Epoch [120/200], d_loss: 1.5351, g_loss: 3.8282\n",
      "Epoch [121/200], d_loss: 2.1358, g_loss: 2.1472\n",
      "Epoch [122/200], d_loss: 1.3884, g_loss: 4.4419\n",
      "Epoch [123/200], d_loss: 1.8389, g_loss: 3.2376\n",
      "Epoch [124/200], d_loss: 0.8126, g_loss: 2.5882\n",
      "Epoch [125/200], d_loss: 0.9610, g_loss: 4.1777\n",
      "Epoch [126/200], d_loss: 7.4591, g_loss: 4.0690\n",
      "Epoch [127/200], d_loss: 1.5593, g_loss: 4.2625\n",
      "Epoch [128/200], d_loss: 1.7531, g_loss: 3.3671\n",
      "Epoch [129/200], d_loss: 4.1446, g_loss: 1.0198\n",
      "Epoch [130/200], d_loss: 2.2781, g_loss: 1.6659\n",
      "Epoch [131/200], d_loss: 0.8028, g_loss: 3.5687\n",
      "Epoch [132/200], d_loss: 1.2289, g_loss: 5.3325\n",
      "Epoch [133/200], d_loss: 1.4839, g_loss: 4.6311\n",
      "Epoch [134/200], d_loss: 2.2554, g_loss: 1.0688\n",
      "Epoch [135/200], d_loss: 3.0660, g_loss: 4.5800\n",
      "Epoch [136/200], d_loss: 2.2267, g_loss: 1.7792\n",
      "Epoch [137/200], d_loss: 1.6839, g_loss: 4.3251\n",
      "Epoch [138/200], d_loss: 1.2121, g_loss: 1.3298\n",
      "Epoch [139/200], d_loss: 2.7743, g_loss: 4.6743\n",
      "Epoch [140/200], d_loss: 1.6912, g_loss: 2.5991\n",
      "Epoch [141/200], d_loss: 0.3833, g_loss: 5.0195\n",
      "Epoch [142/200], d_loss: 0.5597, g_loss: 1.7635\n",
      "Epoch [143/200], d_loss: 1.4825, g_loss: 0.6770\n",
      "Epoch [144/200], d_loss: 3.3139, g_loss: 2.8006\n",
      "Epoch [145/200], d_loss: 1.0634, g_loss: 2.7233\n",
      "Epoch [146/200], d_loss: 0.6113, g_loss: 4.7403\n",
      "Epoch [147/200], d_loss: 0.5744, g_loss: 3.6628\n",
      "Epoch [148/200], d_loss: 1.7842, g_loss: 6.2500\n",
      "Epoch [149/200], d_loss: 1.2481, g_loss: 3.4135\n",
      "Epoch [150/200], d_loss: 0.2875, g_loss: 4.7142\n",
      "Epoch [151/200], d_loss: 1.6748, g_loss: 5.1585\n",
      "Epoch [152/200], d_loss: 2.1618, g_loss: 2.7732\n",
      "Epoch [153/200], d_loss: 0.7727, g_loss: 5.6520\n",
      "Epoch [154/200], d_loss: 2.1822, g_loss: 1.4911\n",
      "Epoch [155/200], d_loss: 1.3304, g_loss: 3.3856\n",
      "Epoch [156/200], d_loss: 1.2284, g_loss: 3.1150\n",
      "Epoch [157/200], d_loss: 0.9327, g_loss: 5.5742\n",
      "Epoch [158/200], d_loss: 0.8740, g_loss: 3.6407\n",
      "Epoch [159/200], d_loss: 3.1693, g_loss: 2.5988\n",
      "Epoch [160/200], d_loss: 1.1341, g_loss: 3.1069\n",
      "Epoch [161/200], d_loss: 1.6804, g_loss: 3.7195\n",
      "Epoch [162/200], d_loss: 1.8007, g_loss: 4.5433\n",
      "Epoch [163/200], d_loss: 5.1454, g_loss: 3.9999\n",
      "Epoch [164/200], d_loss: 3.0134, g_loss: 3.4349\n",
      "Epoch [165/200], d_loss: 2.1937, g_loss: 2.6659\n",
      "Epoch [166/200], d_loss: 1.2666, g_loss: 1.8367\n",
      "Epoch [167/200], d_loss: 1.9105, g_loss: 1.6244\n",
      "Epoch [168/200], d_loss: 1.7675, g_loss: 2.7378\n",
      "Epoch [169/200], d_loss: 1.5274, g_loss: 1.8027\n",
      "Epoch [170/200], d_loss: 1.0577, g_loss: 2.0999\n",
      "Epoch [171/200], d_loss: 4.0807, g_loss: 1.5753\n",
      "Epoch [172/200], d_loss: 2.0208, g_loss: 0.6724\n",
      "Epoch [173/200], d_loss: 1.9520, g_loss: 3.8554\n",
      "Epoch [174/200], d_loss: 0.9332, g_loss: 2.5558\n",
      "Epoch [175/200], d_loss: 1.4523, g_loss: 1.7910\n",
      "Epoch [176/200], d_loss: 1.2827, g_loss: 1.2991\n",
      "Epoch [177/200], d_loss: 1.5787, g_loss: 1.6912\n",
      "Epoch [178/200], d_loss: 1.6593, g_loss: 2.0173\n",
      "Epoch [179/200], d_loss: 1.0010, g_loss: 3.0065\n",
      "Epoch [180/200], d_loss: 2.3770, g_loss: 2.2605\n",
      "Epoch [181/200], d_loss: 0.7883, g_loss: 2.7227\n",
      "Epoch [182/200], d_loss: 1.2459, g_loss: 1.1374\n",
      "Epoch [183/200], d_loss: 2.6897, g_loss: 2.6530\n",
      "Epoch [184/200], d_loss: 3.3255, g_loss: 1.9888\n",
      "Epoch [185/200], d_loss: 1.2136, g_loss: 0.9454\n",
      "Epoch [186/200], d_loss: 0.9544, g_loss: 1.7553\n",
      "Epoch [187/200], d_loss: 0.7692, g_loss: 2.3654\n",
      "Epoch [188/200], d_loss: 0.7266, g_loss: 1.5381\n",
      "Epoch [189/200], d_loss: 0.8428, g_loss: 2.5119\n",
      "Epoch [190/200], d_loss: 1.2000, g_loss: 2.0689\n",
      "Epoch [191/200], d_loss: 1.7951, g_loss: 1.9970\n",
      "Epoch [192/200], d_loss: 1.4238, g_loss: 2.2611\n",
      "Epoch [193/200], d_loss: 1.0143, g_loss: 3.2209\n",
      "Epoch [194/200], d_loss: 0.8182, g_loss: 4.1786\n",
      "Epoch [195/200], d_loss: 0.4813, g_loss: 6.3250\n",
      "Epoch [196/200], d_loss: 1.3386, g_loss: 2.5903\n",
      "Epoch [197/200], d_loss: 0.8395, g_loss: 2.9481\n",
      "Epoch [198/200], d_loss: 1.1245, g_loss: 5.3405\n",
      "Epoch [199/200], d_loss: 2.0863, g_loss: 2.8437\n",
      "Epoch [200/200], d_loss: 0.6283, g_loss: 2.9831\n",
      "Trening završen. Slike su sačuvane u folderu: dataset/generated_images\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.utils as vutils\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Definisanje custom Dataset klase\n",
    "class AstronomyDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = [f for f in os.listdir(root_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.images[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "# Definisanje Generator mreže\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz=100, ngf=64, nc=3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc=3, ndf=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1, 1)  # Vraća 2D tenzor\n",
    "\n",
    "# Inicijalizacija mreža i optimizatora\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "# Funkcija gubitka\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Učitavanje podataka\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = AstronomyDataset(root_dir='dataset/images', transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Kreiranje foldera za čuvanje slika\n",
    "output_dir = 'dataset/generated_images'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Funkcija za čuvanje slika\n",
    "def save_images(epoch, fake_images):\n",
    "    grid = vutils.make_grid(fake_images, normalize=True, padding=2)\n",
    "    img = Image.fromarray(grid.mul(255).permute(1, 2, 0).byte().numpy())\n",
    "    img.save(f'{output_dir}/epoch_{epoch+1}.png')\n",
    "\n",
    "# Funkcija za računanje gradient penalty\n",
    "def gradient_penalty(discriminator, real_images, fake_images, device):\n",
    "    batch_size = real_images.size(0)\n",
    "    epsilon = torch.rand(batch_size, 1, 1, 1, device=device, requires_grad=True)\n",
    "    interpolated_images = epsilon * real_images + (1 - epsilon) * fake_images\n",
    "    interpolated_images = interpolated_images.to(device)\n",
    "    \n",
    "    interpolated_scores = discriminator(interpolated_images)\n",
    "    \n",
    "    gradients = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=interpolated_scores,\n",
    "        grad_outputs=torch.ones_like(interpolated_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    \n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    gradient_norm = gradients.norm(2, dim=1)\n",
    "    gp = ((gradient_norm - 1)**2).mean()\n",
    "    return gp\n",
    "\n",
    "# Trening petlja\n",
    "num_epochs = 200\n",
    "nz = 100  # Veličina ulaznog vektora šuma\n",
    "lambda_gp = 10  # Koeficijent za gradient penalty\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, real_images in enumerate(train_loader):\n",
    "        batch_size = real_images.size(0)\n",
    "        real_images = real_images.to(device)\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # Trening Discriminatora\n",
    "        d_optimizer.zero_grad()\n",
    "        outputs = discriminator(real_images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        \n",
    "        z = torch.randn(batch_size, nz, 1, 1).to(device)\n",
    "        fake_images = generator(z)\n",
    "        outputs = discriminator(fake_images.detach())\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        \n",
    "        gp = gradient_penalty(discriminator, real_images, fake_images, device)\n",
    "        \n",
    "        d_loss = d_loss_real + d_loss_fake + lambda_gp * gp\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # Trening Generatora\n",
    "        g_optimizer.zero_grad()\n",
    "        z = torch.randn(batch_size, nz, 1, 1).to(device)\n",
    "        fake_images = generator(z)\n",
    "        outputs = discriminator(fake_images)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}\")\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            fake_images = generator(torch.randn(64, nz, 1, 1).to(device)).cpu()\n",
    "        save_images(epoch, fake_images)\n",
    "\n",
    "print(f\"Trening završen. Slike su sačuvane u folderu: {output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
